{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "024.VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpRxtS1I1GY7V4Iadv8pA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PANDASANG1231/deeplearn_note/blob/master/024_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIinPrJnnxp"
      },
      "source": [
        "## Note\n",
        "  -  The result of Lenet start a new idea of Conv\n",
        "  -  The result of AlexNet prove that we need to deploy deeper and wider Network\n",
        "  -  The result of VGG shows that we can make the CNN more standard and easy to replicate\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnFXuqV2lQSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c8b94c-f788-4d1b-8b7b-516abc83fb74"
      },
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/deeplearning_note')\n",
        "from tool import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-EGHWAqUwN3"
      },
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec9ZezBhVJZ2",
        "outputId": "69b491b6-065c-4efa-80cb-fd4cf8ac3841"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  9 04:17:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITM5H-zbYwe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f05829-134c-4d39-a095-5960ce912c1c"
      },
      "source": [
        "class VGG_block(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, num_conv, in_channels, out_channels):\n",
        "\n",
        "    super().__init__()\n",
        "    layer = []\n",
        "    for i in range(num_conv):\n",
        "        layer.append(torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding='same'))\n",
        "        layer.append(torch.nn.ReLU())\n",
        "        in_channels = out_channels\n",
        "    layer.append(torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "    self.model = torch.nn.Sequential(*layer)\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return self.model(X)\n",
        "\n",
        "\n",
        "classic_vgg_arch = [(1, 64), (1, 128), (2, 256), (2, 512), (2, 512)]\n",
        "class VGG(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, in_channel_0, vgg_arch):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    model = []\n",
        "    in_channels = in_channel_0\n",
        "    for num_conv, out_channels in classic_vgg_arch:\n",
        "        model.append(VGG_block(num_conv=num_conv, out_channels=out_channels, in_channels=in_channels))\n",
        "        in_channels = out_channels\n",
        "\n",
        "    self.model = torch.nn.Sequential(*model, torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=out_channels*7*7, out_features=4096), torch.nn.ReLU(), torch.nn.Dropout(p=0.5),\n",
        "        torch.nn.Linear(in_features=4096, out_features=4096), torch.nn.ReLU(), torch.nn.Dropout(p=0.5),\n",
        "        torch.nn.Linear(in_features=4096, out_features=10),) \n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return self.model(X)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.randn(size=(1, 1, 224, 224))\n",
        "vgg = VGG(vgg_arch=classic_vgg_arch, in_channel_0=1)\n",
        "for layer in vgg.model:\n",
        "  x = layer(x)\n",
        "  print(layer.__class__.__name__, x.shape) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG_block torch.Size([1, 64, 112, 112])\n",
            "VGG_block torch.Size([1, 128, 56, 56])\n",
            "VGG_block torch.Size([1, 256, 28, 28])\n",
            "VGG_block torch.Size([1, 512, 14, 14])\n",
            "VGG_block torch.Size([1, 512, 7, 7])\n",
            "Flatten torch.Size([1, 25088])\n",
            "Linear torch.Size([1, 4096])\n",
            "ReLU torch.Size([1, 4096])\n",
            "Dropout torch.Size([1, 4096])\n",
            "Linear torch.Size([1, 4096])\n",
            "ReLU torch.Size([1, 4096])\n",
            "Dropout torch.Size([1, 4096])\n",
            "Linear torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjWkCXWhoX4o"
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Resize(size=224)\n",
        "             ])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./', train=True, download=True, transform=transforms)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./', train=False, download=True, transform=transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Y7ZkTSYrCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327cf6eb-1d9a-4440-a663-1828efed162c"
      },
      "source": [
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = VGG(vgg_arch=[(x, x1//4) for x,x1 in classic_vgg_arch], in_channel_0=1)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"This is a simple VGG-11...\")\n",
        "x = torch.randn(size=(1, 1, 224, 224))\n",
        "for layer in model.model:\n",
        "  x = layer(x)\n",
        "  print(layer.__class__.__name__, x.shape) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a simple VGG-11...\n",
            "VGG_block torch.Size([1, 64, 112, 112])\n",
            "VGG_block torch.Size([1, 128, 56, 56])\n",
            "VGG_block torch.Size([1, 256, 28, 28])\n",
            "VGG_block torch.Size([1, 512, 14, 14])\n",
            "VGG_block torch.Size([1, 512, 7, 7])\n",
            "Flatten torch.Size([1, 25088])\n",
            "Linear torch.Size([1, 4096])\n",
            "ReLU torch.Size([1, 4096])\n",
            "Dropout torch.Size([1, 4096])\n",
            "Linear torch.Size([1, 4096])\n",
            "ReLU torch.Size([1, 4096])\n",
            "Dropout torch.Size([1, 4096])\n",
            "Linear torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CL1IU7Yy1E",
        "outputId": "79de4fba-889d-41f6-ac37-f2f46c7b1010"
      },
      "source": [
        "train_p2(epoch_num=10, \n",
        "         model=model,  \n",
        "         loss=loss, \n",
        "         lr=0.05, \n",
        "         train_data_iter=train_dataloader,\n",
        "         test_data_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optim_type=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.983, train acc 0.635, test acc 0.835\n",
            "loss 0.352, train acc 0.869, test acc 0.884\n",
            "loss 0.277, train acc 0.897, test acc 0.893\n",
            "loss 0.238, train acc 0.911, test acc 0.900\n",
            "loss 0.203, train acc 0.925, test acc 0.902\n",
            "loss 0.175, train acc 0.935, test acc 0.907\n",
            "loss 0.146, train acc 0.945, test acc 0.915\n",
            "loss 0.121, train acc 0.956, test acc 0.917\n",
            "loss 0.094, train acc 0.966, test acc 0.919\n",
            "loss 0.073, train acc 0.973, test acc 0.922\n",
            "Calculation Ability: 12327.9 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQrTsaENmWhy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}