{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "022.Lenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY6Mi3j0D2s5F6dfHIFfV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PANDASANG1231/deeplearn_note/blob/master/022_Lenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnFXuqV2lQSx"
      },
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# sys.path.append('/content/drive/My Drive/deeplearn_note/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNYvB6sURU6H"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "## 定义metrics\n",
        "class Accumulator():\n",
        "    \"\"\"A simple Accumulator which help accumulate a list while evaluation\n",
        "    \"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.] * n\n",
        "    \n",
        "    def add(self, *args):\n",
        "        for arg in args:\n",
        "            self.data = [a + float(b) for a,b in zip(self.data, arg)]\n",
        "    \n",
        "    def reset(self):\n",
        "        self.data = [0.] * len(self.data)\n",
        "    \n",
        "    def __get_item__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 定义metric\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"计算预测正确的数量。\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "\n",
        "def accuracy_iter(model, data_iter):\n",
        "    \"\"\"AI is creating summary for accuracy_iter\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Function of Tensor\n",
        "        Return a single Tensor\n",
        "    data_iter : Iterator\n",
        "        Usually an iterator yields batch data\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of floats\n",
        "        return [loss_of_average, accuracy_of_average, false_rate_of_average]\n",
        "    \"\"\"\n",
        "    \n",
        "    accu = Accumulator(3)\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for X, y in data_iter:\n",
        "            y_hat = model(X)\n",
        "            cnt = len(y)\n",
        "            acc_t = (y_hat.argmax(axis=1) == y).sum()\n",
        "            acc_f = (y_hat.argmax(axis=1) != y).sum()\n",
        "            accu.add([cnt, acc_t, acc_f])\n",
        "            \n",
        "    return [x/accu.data[0] for x in accu.data][1:]\n",
        "\n",
        "\n",
        "def accuracy_iter_gpu(model, data_iter, device=None):\n",
        "    \"\"\"AI is creating summary for accuracy_iter\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Function of Tensor\n",
        "        Return a single Tensor\n",
        "    data_iter : Iterator\n",
        "        Usually an iterator yields batch data\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of floats\n",
        "        return [loss_of_average, accuracy_of_average, false_rate_of_average]\n",
        "    \"\"\"\n",
        "    \n",
        "    if isinstance(model, torch.nn.Module):\n",
        "      model.eval()\n",
        "      if not device:\n",
        "        device = next(iter(model.parameters())).device\n",
        "\n",
        "    accu = Accumulator(3)\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for X, y in data_iter:\n",
        "\n",
        "          if isinstance(X, list):\n",
        "            X = [x.to(device) for x in X]\n",
        "          else:\n",
        "            X = X.to(device)\n",
        "          \n",
        "          y = y.to(device)\n",
        "          y_hat = model(X)\n",
        "          cnt = len(y)\n",
        "          acc_t = (y_hat.argmax(axis=1) == y).sum()\n",
        "          acc_f = (y_hat.argmax(axis=1) != y).sum()\n",
        "          accu.add([cnt, acc_t, acc_f])\n",
        "            \n",
        "    return [x/accu.data[0] for x in accu.data][1:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Animation Class\n",
        "from IPython import display\n",
        "\n",
        "class Animation():\n",
        "    \n",
        "    def __init__(self, epoch_show_num, xlim=None, ylim=[0, 10], secondary=True, xlabel=\"Epoch\"):\n",
        "        \n",
        "        import matplotlib.pyplot as plt\n",
        "        self.epoch_show_num = epoch_show_num\n",
        "        self.fig, self.ax = plt.subplots(1, 1, figsize=(8,4))\n",
        "        self.ax.set_xticks(range(epoch_show_num))\n",
        "        self.ax.set_xlabel(xlabel)\n",
        "        # self.ax.set_ylim(*ylim)\n",
        "        self.data = {\"l\": []}\n",
        "        \n",
        "        if secondary == True:\n",
        "            self.ax2 = self.ax.twinx()\n",
        "            self.data[\"r\"] = []\n",
        "            \n",
        "        self.secondary = secondary\n",
        "\n",
        "    def add_data(self, data, side='l'):\n",
        "                \n",
        "        if self.data[side]:\n",
        "            self.data[side] = [a + [x] for a, x in zip(self.data[side], data)]\n",
        "        else:\n",
        "            self.data[side] = [[x] for x in data]\n",
        "            \n",
        "        \n",
        "    def add(self, data_l, data_r=None, legends_l=None, legends_r=None):\n",
        "                \n",
        "        if legends_l is None:\n",
        "            legends_l = list(range(len(data_l)))\n",
        "        if legends_r is None:\n",
        "            legends_r = list(range(len(data_r)))\n",
        "            \n",
        "        if data_l:\n",
        "            self.add_data(data_l, \"l\")\n",
        "        if data_r:\n",
        "            self.add_data(data_r, \"r\")\n",
        "        \n",
        "        self.ax.cla()\n",
        "        self.ax2.cla()\n",
        "        \n",
        "        alpha_l = 1\n",
        "        alpha_r = 1\n",
        "                \n",
        "        for data_l_list, label in zip(self.data['l'], legends_l):\n",
        "            self.ax.plot(range(len(data_l_list)), data_l_list, label=label, alpha=alpha_l, color='b')\n",
        "            alpha_l /= 2\n",
        "        \n",
        "        if self.secondary:\n",
        "            for data_r_list, label in zip(self.data['r'], legends_r):\n",
        "                self.ax2.plot(range(len(data_r_list)), data_r_list, label=label, color='r', alpha=alpha_r, linestyle=\"--\")\n",
        "                self.ax2.set_xticks(range(self.epoch_show_num))\n",
        "                self.ax2.set_ylim(0.5, 1)\n",
        "                alpha_r /= 2\n",
        "\n",
        "\n",
        "        plt.legend()\n",
        "        \n",
        "        if self.secondary:\n",
        "            plt.grid(\"minor\", axis='both')\n",
        "        else:\n",
        "            plt.grid(\"major\", axis='both')\n",
        "\n",
        "        print(legends_l , legends_r)\n",
        "        print(data_l , data_r)\n",
        "        \n",
        "        display.display(self.fig)\n",
        "        \n",
        "\n",
        "        display.clear_output(wait=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-EGHWAqUwN3"
      },
      "source": [
        "import torch\n",
        "\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec9ZezBhVJZ2",
        "outputId": "2442dc76-13e2-472b-e5e6-a5e92a5f5f31"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov  8 06:14:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    33W / 250W |   1045MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITM5H-zbYwe6"
      },
      "source": [
        "class Lenet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=1, out_channels=6, padding=2, kernel_size=5, stride=1), \n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=400, out_features=120),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=120, out_features=84),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=84, out_features=10),\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return self.model(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DK_KRhWU_k"
      },
      "source": [
        "def train_epoch_p2(model, loss, optimizer, train_data_iter, test_data_iter, device):\n",
        "    \"\"\"training function for one epoch, General in CNN style structrue, will use GPU run model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Model\n",
        "        Use pytoch model or model in pytorch variables\n",
        "    loss : torch.nn.Module\n",
        "        Loss function\n",
        "    optimizer : torch.optims.Optimizer\n",
        "        Must be torch's Optimizer Class\n",
        "    train_data_iter : Iterator\n",
        "        Iterate data in Train\n",
        "    test_data_iter : Iterator\n",
        "        Iterate data in Test\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List\n",
        "        final_metrics = [train_loss, train_accuracy, test_accuracy]\n",
        "    \"\"\"\n",
        "\n",
        "    accu = Accumulator(3)\n",
        "    time_accu = Accumulator(2)\n",
        "\n",
        "\n",
        "    for batch_X, batch_y in train_data_iter:\n",
        "        time_ = time.time()\n",
        "        batch_X, batch_y = batch_X.to(device=device), batch_y.to(device=device)\n",
        "\n",
        "        batch_y_hat = model(batch_X)\n",
        "        batch_loss = loss(batch_y_hat, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        time_ = time.time() - time_\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n = len(batch_y)\n",
        "            batch_acc = accuracy(batch_y_hat, batch_y)\n",
        "            accu.add([n, n*batch_loss, batch_acc])\n",
        "            time_accu.add([time_, n])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_metric = [x / accu.data[0] for x in accu.data][1:]\n",
        "    test_acc = accuracy_iter_gpu(model, test_data_iter, device)\n",
        "    final_metrics = train_metric + [test_acc[0]]\n",
        "\n",
        "    return final_metrics, [x / time_accu.data[0] for x in time_accu.data][1:]\n",
        "\n",
        "\n",
        "\n",
        "def train_p2(epoch_num, model, loss, lr, train_data_iter, test_data_iter, device, optim_type=\"SGD\"):\n",
        "    \"\"\"training function, General in CNN style structrue, will use GPU run model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    epoch_num: Int\n",
        "        Numbers to train\n",
        "    model : Model\n",
        "        Use pytoch model or model in pytorch variables\n",
        "    loss : torch.nn.Module\n",
        "        Loss function\n",
        "    lr : Learning rate\n",
        "    train_data_iter : Iterator\n",
        "        Iterate data in Train\n",
        "    test_data_iter : Iterator\n",
        "        Iterate data in Test\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List\n",
        "        final_metrics = [train_loss, train_accuracy, test_accuracy]\n",
        "    \"\"\"\n",
        "\n",
        "    def init_weights(m):\n",
        "        if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
        "          torch.nn.init.xavier_uniform_(m.weight)\n",
        "    \n",
        "    model.apply(init_weights)\n",
        "    model.to(device=device)\n",
        "\n",
        "    if optim_type == \"SGD\":\n",
        "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
        "    else:\n",
        "        if lr > 0.01:\n",
        "            lr = 0.01\n",
        "        optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "\n",
        "    # animation = Animation(epoch_show_num=epoch_num, secondary=True)\n",
        "    \n",
        "    for _ in range(epoch_num):\n",
        "        final_metrics, examplist = train_epoch_p2(model, loss, optimizer, train_data_iter, test_data_iter, device)\n",
        "        # animation.add(data_l=[final_metrics[0]], data_r=final_metrics[1:], \n",
        "        #               legends_l=[\"train_loss\"], legends_r=[\"train_accuracy\", \"test_accuracy\"])\n",
        "      \n",
        "        print(f'loss {final_metrics[0]:.3f}, train acc {final_metrics[1]:.3f}, '\n",
        "              f'test acc {final_metrics[2]:.3f}')\n",
        "        \n",
        "    print(f'Calculation Ability: {examplist[0]:.1f} examples/sec on {str(device)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjWkCXWhoX4o"
      },
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(root='./', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Y7ZkTSYrCj"
      },
      "source": [
        "batch_size = 256\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=False)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = Lenet()\n",
        "loss = torch.nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CL1IU7Yy1E",
        "outputId": "7868bdac-88b2-47bf-8871-ca12e63e5e9a"
      },
      "source": [
        "train_p2(epoch_num=10, \n",
        "         model=Lenet(),  \n",
        "         loss=loss, \n",
        "         lr=0.9, \n",
        "         train_data_iter=train_dataloader,\n",
        "         test_data_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optim_type=\"Adam\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 1.094, train acc 0.579, test acc 0.758\n",
            "loss 0.530, train acc 0.799, test acc 0.810\n",
            "loss 0.442, train acc 0.836, test acc 0.830\n",
            "loss 0.403, train acc 0.850, test acc 0.841\n",
            "loss 0.376, train acc 0.860, test acc 0.856\n",
            "loss 0.353, train acc 0.868, test acc 0.863\n",
            "loss 0.335, train acc 0.875, test acc 0.863\n",
            "loss 0.323, train acc 0.878, test acc 0.872\n",
            "loss 0.313, train acc 0.882, test acc 0.859\n",
            "loss 0.302, train acc 0.888, test acc 0.878\n",
            "60896.9 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6oujUGpZCyQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}