{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "027.BatchNorm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOzgAn3lLflSiViEHc/6UVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PANDASANG1231/deeplearn_note/blob/main/027_BatchNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnFXuqV2lQSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20239a40-b148-43a2-ec54-fe83a7999a52"
      },
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/deeplearning_note')\n",
        "from tool import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-EGHWAqUwN3"
      },
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gupbse07UBfF"
      },
      "source": [
        "This is a simple implementation of Batch_norm.\n",
        "\n",
        "**Note**:\n",
        "  \n",
        "1. To a MLP(Table data), batch_norm is averageing on dim=0, feature-level average\n",
        "2. To a CNN(Image data), batch_norm is averageing on dim=(0,2,3), channel-level average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec9ZezBhVJZ2"
      },
      "source": [
        "def batch_norm(X, gamma, beta, moving_average, moving_var, eps, momentum):\n",
        "\n",
        "  if not torch.is_grad_enabled():\n",
        "    Xhat = (X - moving_average) / torch.sqrt(moving_var + eps)\n",
        "  else:\n",
        "    if len(X.shape) == 2:\n",
        "      mean = X.mean(dim=0)\n",
        "      var = ((X - mean) ** 2).mean(dim=0)\n",
        "    elif len(X.shape) == 4:\n",
        "      mean = X.mean(dim=(0,2,3), keepdim=True)\n",
        "      var = ((X - mean) ** 2).mean(dim=(0,2,3), keepdim=True)\n",
        "\n",
        "    Xhat = (X - mean) / torch.sqrt(var + eps)\n",
        "    moving_average = (1 - momentum) * mean + momentum * moving_average\n",
        "    moving_var = (1 - momentum) * var + momentum * moving_var\n",
        "\n",
        "  Y_hat = Xhat * gamma + beta\n",
        "\n",
        "  return Y_hat, moving_average.data, moving_var.data\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3nBgm23MFHP"
      },
      "source": [
        "class BatchNorm(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, num_features, nums_dim):\n",
        "\n",
        "    super().__init__()\n",
        "    self.num_features = num_features\n",
        "    if nums_dim == 2:\n",
        "      self.size = (1, num_features)\n",
        "    elif nums_dim == 4:\n",
        "      self.size = (1, num_features, 1, 1)\n",
        "    \n",
        "    self.gamma = torch.nn.Parameter(torch.ones(self.size))\n",
        "    self.beta = torch.nn.Parameter(torch.zeros(self.size))\n",
        "    self.moving_average = torch.ones(self.size)\n",
        "    self.moving_var = torch.zeros(self.size)\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    if self.moving_average.device != X.device:\n",
        "      \n",
        "      self.moving_average = self.moving_average.to(X.device)\n",
        "      self.moving_var = self.moving_var.to(X.device)\n",
        "\n",
        "    Y, self.moving_average, self.moving_var = batch_norm(\n",
        "        X, self.gamma, self.beta, self.moving_average, self.moving_var, eps=1e-5, momentum=0.9\n",
        "        )\n",
        "    \n",
        "    return Y\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARWWkvhVRF_"
      },
      "source": [
        "Test on Lenet with or without batchnorm\n",
        "\n",
        "1. Batch norm will not change the performance. (It is not the case here, but here Lenet is not fully trained)\n",
        "\n",
        "2. It will accelerate the speed of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjWkCXWhoX4o"
      },
      "source": [
        "class Lenet_withbn(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=1, out_channels=6, padding=2, kernel_size=5, stride=1), \n",
        "        BatchNorm(num_features=6, nums_dim=4), \n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "        BatchNorm(num_features=16, nums_dim=4), \n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=400, out_features=120),\n",
        "        BatchNorm(num_features=120, nums_dim=2), \n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=120, out_features=84),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=84, out_features=10),\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return self.model(X)\n",
        "\n",
        "\n",
        "class Lenet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=1, out_channels=6, padding=2, kernel_size=5, stride=1), \n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=400, out_features=120),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=120, out_features=84),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=84, out_features=10),\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return self.model(X)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvcEKNgdFnH4",
        "outputId": "c511c54a-8c88-45b2-8982-c5960f939d4f"
      },
      "source": [
        "x = torch.ones((1, 1, 28, 28))\n",
        "\n",
        "print(\"Normal Lent .......\")\n",
        "le = Lenet()\n",
        "for layer in le.model:\n",
        "    x = layer(x)\n",
        "    print(layer.__class__.__name__, x.shape)\n",
        "\n",
        "x = torch.ones((1, 1, 28, 28))\n",
        "\n",
        "print(\"BN Lent .......\")\n",
        "le = Lenet_withbn()\n",
        "for layer in le.model:\n",
        "    x = layer(x)\n",
        "    print(layer.__class__.__name__, x.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Lent .......\n",
            "Conv2d torch.Size([1, 6, 28, 28])\n",
            "Sigmoid torch.Size([1, 6, 28, 28])\n",
            "AvgPool2d torch.Size([1, 6, 14, 14])\n",
            "Conv2d torch.Size([1, 16, 10, 10])\n",
            "Sigmoid torch.Size([1, 16, 10, 10])\n",
            "AvgPool2d torch.Size([1, 16, 5, 5])\n",
            "Flatten torch.Size([1, 400])\n",
            "Linear torch.Size([1, 120])\n",
            "Sigmoid torch.Size([1, 120])\n",
            "Linear torch.Size([1, 84])\n",
            "Sigmoid torch.Size([1, 84])\n",
            "Linear torch.Size([1, 10])\n",
            "BN Lent .......\n",
            "Conv2d torch.Size([1, 6, 28, 28])\n",
            "BatchNorm torch.Size([1, 6, 28, 28])\n",
            "Sigmoid torch.Size([1, 6, 28, 28])\n",
            "AvgPool2d torch.Size([1, 6, 14, 14])\n",
            "Conv2d torch.Size([1, 16, 10, 10])\n",
            "BatchNorm torch.Size([1, 16, 10, 10])\n",
            "Sigmoid torch.Size([1, 16, 10, 10])\n",
            "AvgPool2d torch.Size([1, 16, 5, 5])\n",
            "Flatten torch.Size([1, 400])\n",
            "Linear torch.Size([1, 120])\n",
            "BatchNorm torch.Size([1, 120])\n",
            "Sigmoid torch.Size([1, 120])\n",
            "Linear torch.Size([1, 84])\n",
            "Sigmoid torch.Size([1, 84])\n",
            "Linear torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9PHA8ckMYtS"
      },
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(root=\"./\",train=True,download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root=\"./\",train=False,download=True,transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Y7ZkTSYrCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e52797d-b1f3-48e7-f2d0-4f943cddf4c8"
      },
      "source": [
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_p2(epoch_num=10, \n",
        "         model=Lenet(),  \n",
        "         loss=loss, \n",
        "         lr=0.05, \n",
        "         train_data_iter=train_dataloader,\n",
        "         test_data_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optim_type=\"Adam\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.902, train acc 0.653, test acc 0.781\n",
            "loss 0.477, train acc 0.821, test acc 0.833\n",
            "loss 0.414, train acc 0.846, test acc 0.849\n",
            "loss 0.382, train acc 0.856, test acc 0.855\n",
            "loss 0.355, train acc 0.866, test acc 0.863\n",
            "loss 0.337, train acc 0.873, test acc 0.855\n",
            "loss 0.322, train acc 0.878, test acc 0.865\n",
            "loss 0.314, train acc 0.883, test acc 0.867\n",
            "loss 0.305, train acc 0.886, test acc 0.867\n",
            "loss 0.297, train acc 0.888, test acc 0.874\n",
            "Calculation Ability: 35210.3 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CL1IU7Yy1E",
        "outputId": "b48ca71e-db20-44ad-8241-61b2aa63c21a"
      },
      "source": [
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_p2(epoch_num=10, \n",
        "         model=Lenet_withbn(),  \n",
        "         loss=loss, \n",
        "         lr=0.05, \n",
        "         train_data_iter=train_dataloader,\n",
        "         test_data_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optim_type=\"Adam\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.528, train acc 0.813, test acc 0.847\n",
            "loss 0.340, train acc 0.876, test acc 0.872\n",
            "loss 0.294, train acc 0.893, test acc 0.876\n",
            "loss 0.266, train acc 0.901, test acc 0.895\n",
            "loss 0.248, train acc 0.908, test acc 0.880\n",
            "loss 0.231, train acc 0.915, test acc 0.900\n",
            "loss 0.222, train acc 0.916, test acc 0.885\n",
            "loss 0.205, train acc 0.924, test acc 0.893\n",
            "loss 0.190, train acc 0.930, test acc 0.901\n",
            "loss 0.186, train acc 0.930, test acc 0.901\n",
            "Calculation Ability: 18956.4 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQrTsaENmWhy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}