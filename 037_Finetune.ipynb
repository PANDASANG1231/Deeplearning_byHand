{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "037.Finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpuHFh9fWVT+ufrFSRCdfQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PANDASANG1231/Deeplearning_byHand/blob/main/037_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnFXuqV2lQSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fabcc5a-2a97-4ac0-bfdf-dc4b4318f6f3"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/deeplearning_note')\n",
        "from tool import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install d2l"
      ],
      "metadata": {
        "id": "W1PWmio23Hin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SemXnflYY1X",
        "outputId": "8479fdd8-e232-4510-8935-c175d5dbfc23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 30 06:11:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet Finetune vs Resnet\n",
        "\n",
        " - Finetune Use Resnet pretrain model. So, we need to do some preprocess\n",
        "   - The resnet model has normalize, so we need to do that as well.\n",
        "   - The resnet has a input size of 224, so we need to do the resize.\n"
      ],
      "metadata": {
        "id": "MDarzT3O41nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from d2l import torch as d2l\n",
        "\n",
        "d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
        "\n",
        "data_dir = d2l.download_extract('hotdog')"
      ],
      "metadata": {
        "id": "MFbTCpKB3Dq_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = torchvision.transforms.Normalize(\n",
        "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "train_augs = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    normalize])\n",
        "\n",
        "test_augs = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    normalize])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_augs)\n",
        "test_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_augs)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "aLwIFWNGwJMk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Finetune\n",
        "\n",
        " - No pretrain, use xavier as weight initiate\n",
        " - learning_rate = 0.05, final accuracy is 0.834\n",
        " - training speed: 608 examples/sec on cuda"
      ],
      "metadata": {
        "id": "bazmo924fKWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(pretrained=False)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
        "\n",
        "def init_xavier(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "resnet.apply(init_xavier)\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.05\n",
        "optimizer = torch.optim.Adam(params=resnet.parameters(), lr=learning_rate)\n",
        "\n",
        "train_p2(num_epochs=10, \n",
        "         net=resnet,  \n",
        "         loss=loss, \n",
        "         train_iter=train_dataloader,\n",
        "         test_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optimizer=optimizer)"
      ],
      "metadata": {
        "id": "EGdtTSUWIGOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ad055a-3371-40bf-eb66-f19d379b7e07"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "loss 2.008, train acc 0.534, test acc 0.623\n",
            "loss 0.593, train acc 0.757, test acc 0.799\n",
            "loss 0.419, train acc 0.806, test acc 0.823\n",
            "loss 0.406, train acc 0.826, test acc 0.831\n",
            "loss 0.393, train acc 0.829, test acc 0.836\n",
            "loss 0.396, train acc 0.825, test acc 0.810\n",
            "loss 0.376, train acc 0.831, test acc 0.850\n",
            "loss 0.373, train acc 0.828, test acc 0.869\n",
            "loss 0.371, train acc 0.830, test acc 0.846\n",
            "loss 0.373, train acc 0.837, test acc 0.834\n",
            "608.9 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetune(different learning rate)\n",
        "\n",
        "  - Just xavier last fully connected layer\n",
        "  - Different learning rate in different layer, last layer 10 times\n",
        "  - learning rate is 0.0001, but accuracy is 0.963. (Far better)\n",
        "  - training speed is the same, 608 examples per sec on cuda\n"
      ],
      "metadata": {
        "id": "dk7BdjXVfesr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
        "nn.init.xavier_uniform_(resnet.fc.weight)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.0001\n",
        "param_norm = [param for name, param in resnet.named_parameters() if name not in ['fc.weight', 'fc.bias']]\n",
        "optimizer = torch.optim.Adam(params=[{\"params\": param_norm},\n",
        "                                    {\"params\": resnet.fc.parameters(), \"lr\": learning_rate * 10}], lr=learning_rate)\n",
        "\n",
        "\n",
        "train_p2(num_epochs=10, \n",
        "         net=resnet,  \n",
        "         loss=loss, \n",
        "         train_iter=train_dataloader,\n",
        "         test_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optimizer=optimizer)"
      ],
      "metadata": {
        "id": "9JDRaSE7A2mS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efebda40-c810-45db-bf1b-6803a5b2b320"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "loss 0.308, train acc 0.881, test acc 0.938\n",
            "loss 0.136, train acc 0.946, test acc 0.948\n",
            "loss 0.135, train acc 0.951, test acc 0.938\n",
            "loss 0.125, train acc 0.950, test acc 0.944\n",
            "loss 0.091, train acc 0.966, test acc 0.944\n",
            "loss 0.086, train acc 0.968, test acc 0.960\n",
            "loss 0.065, train acc 0.975, test acc 0.963\n",
            "loss 0.071, train acc 0.974, test acc 0.938\n",
            "loss 0.067, train acc 0.972, test acc 0.949\n",
            "loss 0.061, train acc 0.980, test acc 0.954\n",
            "608.2 examples/sec on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetune(require grad=True)\n",
        "  - Just xavier last fully connected layer\n",
        "  - Only update grads in the last \n",
        "  - learning rate is 0.0035, but accuracy is 0.926. (Far better)\n",
        "  - training speed is the faster(3 times), 1650 examples per sec on cuda"
      ],
      "metadata": {
        "id": "bpCBYAOk6utL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
        "nn.init.xavier_uniform_(resnet.fc.weight)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.0035\n",
        "\n",
        "for name, param in resnet.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.Adam(params=resnet.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "train_p2(num_epochs=10, \n",
        "         net=resnet,  \n",
        "         loss=loss, \n",
        "         train_iter=train_dataloader,\n",
        "         test_iter=test_dataloader,\n",
        "         device=device,\n",
        "         optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_XtUVcvA7X_",
        "outputId": "a2d1a9d1-a4a3-4d23-d5b0-16165dace85d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "loss 0.579, train acc 0.715, test acc 0.890\n",
            "loss 0.300, train acc 0.873, test acc 0.905\n",
            "loss 0.277, train acc 0.881, test acc 0.910\n",
            "loss 0.241, train acc 0.904, test acc 0.920\n",
            "loss 0.235, train acc 0.905, test acc 0.926\n",
            "loss 0.249, train acc 0.900, test acc 0.925\n",
            "loss 0.243, train acc 0.902, test acc 0.921\n",
            "loss 0.227, train acc 0.901, test acc 0.929\n",
            "loss 0.218, train acc 0.916, test acc 0.915\n",
            "loss 0.232, train acc 0.904, test acc 0.926\n",
            "1650.2 examples/sec on cuda\n"
          ]
        }
      ]
    }
  ]
}